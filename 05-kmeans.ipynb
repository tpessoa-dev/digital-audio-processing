{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#262626; text-align: center;\">\n",
    "<img src=\"https://fiapfunctions.blob.core.windows.net/datasets/capa.png\">\n",
    "</div>\n",
    "\n",
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl https://meriatdatasets.blob.core.windows.net/public/digital-audio-processing/drum_samples.zip -o audios/drum_samples.zip\n",
    "!curl https://meriatdatasets.blob.core.windows.net/public/digital-audio-processing/125_bounce.wav -o audios/125_bounce.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip audios/drum_samples.zip -d audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm audios/drum_samples.zip\n",
    "!ls audios/drum_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import librosa, librosa.display\n",
    "import IPython.display as ipd\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paper da criação do pacote **`mir_eval`**.\n",
    "\n",
    "[A TRANSPARENT IMPLEMENTATION OF COMMON MIR METRICS](https://colinraffel.com/publications/ismir2014mir_eval.pdf)\n",
    "\n",
    "Documentação: http://craffel.github.io/mir_eval/"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!pip install mir_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mir_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Feature Extraction\n",
    "\n",
    "De alguma forma, devemos extrair as características do nosso sinal de áudio que são mais relevantes para o problema que estamos tentando resolver. \n",
    "\n",
    "Por exemplo, se quisermos classificar instrumentos por **timbre**, queremos características que possam nos ajudar a destinguir sons por seu **timbre** e não por seu **tom**.\n",
    "\n",
    "> Este processo é conhecido como `extração de recursos` (feature extraction).\n",
    "\n",
    "Para esta tarefa vamos analisar vinte arquivos de áudio: \n",
    "\n",
    "* dez amostras de **`kick drum`** ou **bumbo** \n",
    "* dez amostras de **`snare drum`** ou **caixa**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kick_signals = [ librosa.load(p)[0] for p in Path().glob('audios/drum_samples/train/kick_*.mp3') ]\n",
    "snare_signals = [ librosa.load(p)[0] for p in Path().glob('audios/drum_samples/train/snare_*.mp3') ]\n",
    "\n",
    "print(len(kick_signals))\n",
    "print(len(snare_signals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kick drum signals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "\n",
    "for i, x in enumerate(kick_signals):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    librosa.display.waveplot(x[:10000], alpha=0.8)\n",
    "    plt.ylim(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Snare drum signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "\n",
    "for i, x in enumerate(snare_signals):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    librosa.display.waveplot(x[:10000], alpha=0.8)\n",
    "    plt.ylim(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Feature Vector\n",
    "\n",
    "Vamos criar um vetor de recursos (Feature Vector), para armazenar nossa coleção de recursos. \n",
    "\n",
    "Abaixo temos o método `extract_features`, que é uma função simples para construção de um vetor de recursos bidimensionais a partir de um determinado sinal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(signal):\n",
    "    return [\n",
    "        librosa.feature.zero_crossing_rate(signal)[0, 0],\n",
    "        librosa.feature.spectral_centroid(signal)[0, 0]\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kick_features = np.array([extract_features(x) for x in kick_signals])\n",
    "snare_features = np.array([extract_features(x) for x in snare_signals])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot do histograma das características de cada uma das classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "plt.hist(kick_features[:,0], color='b', range=(0, 0.2), alpha=0.5, bins=20)\n",
    "plt.hist(snare_features[:,0], color='r', range=(0, 0.2), alpha=0.5, bins=20)\n",
    "plt.legend(('kicks', 'snares'))\n",
    "plt.xlabel('Zero Crossing Rate')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "plt.hist(kick_features[:,1], color='b', range=(0, 4000), bins=30, alpha=0.6)\n",
    "plt.hist(snare_features[:,1], color='r', range=(0, 4000), bins=30, alpha=0.6)\n",
    "plt.legend(('kicks', 'snares'))\n",
    "plt.xlabel('Spectral Centroid (frequency bin)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling\n",
    "\n",
    "As características que usamos no exemplo anterior incluíam a taxa de travessia no zero (zero crossing rate) e o centróide espectral (spectral centroid). Esses dois recursos são expressos usando unidades diferentes. Essa discrepância pode gerar problemas ao realizar uma classificação a posteriori. Portanto, normalizaremos cada vetor de recursos em uma faixa comum, armazenando também os parâmetros desta normalização para uso futuro.\n",
    "\n",
    "Neste caso usaremos o `sklearn.preprocessing.MinMaxScaler`, que retorna uma série de valores escalonados de tal forma que cada dimensão do recurso está na faixa de -1 a 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_table = np.vstack((kick_features, snare_features))\n",
    "\n",
    "print(feature_table.shape)\n",
    "\n",
    "# Escalar cada dimensão de recurso para a faixa entre -1 e 1:\n",
    "scaler = sklearn.preprocessing.MinMaxScaler(feature_range=(-1, 1))\n",
    "training_features = scaler.fit_transform(feature_table)\n",
    "\n",
    "print(training_features.min(axis=0))\n",
    "print(training_features.max(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot das características dimensionadas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(training_features[:10,0], training_features[:10,1], c='b')\n",
    "plt.scatter(training_features[10:,0], training_features[10:,1], c='r')\n",
    "plt.xlabel('Zero Crossing Rate')\n",
    "plt.ylabel('Spectral Centroid')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means Clustering\n",
    "\n",
    "Para este exemplo, vamos utilizar uma técnica de aprendizagem não supervisionada. Mesmo que seja abundante a quantidade de dados rotuládos, para a classificação ou outras atividades com áudio, queremos medir a precisão em que será possível agrupar nossos dados com base em suas características.\n",
    "\n",
    "Para esta prova rápida, a técnica de clustering é uma ótima opção."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "x, fs = librosa.load('audios/125_bounce.wav')\n",
    "ipd.Audio(x, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "librosa.display.waveplot(x, fs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Onset Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "onset_frames = librosa.onset.onset_detect(x, sr=fs, delta=0.04, wait=4)\n",
    "onset_times = librosa.frames_to_time(onset_frames, sr=fs)\n",
    "onset_samples = librosa.frames_to_samples(onset_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "x_with_beeps = mir_eval.sonify.clicks(onset_times, fs, length=len(x))\n",
    "ipd.Audio(x + x_with_beeps, rate=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(x, fs):\n",
    "    zcr = librosa.zero_crossings(x).sum()\n",
    "    energy = scipy.linalg.norm(x)\n",
    "    return [zcr, energy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "frame_sz = int(fs*0.090)\n",
    "a = [extract_features(x[i:i+frame_sz], fs) for i in onset_samples]\n",
    "features = np.array(a)\n",
    "\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "min_max_scaler = sklearn.preprocessing.MinMaxScaler(feature_range=(-1, 1))\n",
    "features_scaled = min_max_scaler.fit_transform(features)\n",
    "\n",
    "print(features_scaled.shape)\n",
    "print(features_scaled.min(axis=0))\n",
    "print(features_scaled.max(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plt.scatter(features_scaled[:,0], features_scaled[:,1])\n",
    "plt.xlabel('Zero Crossing Rate (scaled)')\n",
    "plt.ylabel('Spectral Centroid (scaled)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model = sklearn.cluster.KMeans(n_clusters=2)\n",
    "labels = model.fit_predict(features_scaled)\n",
    "\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plt.scatter(features_scaled[labels==0,0], features_scaled[labels==0,1], c='b')\n",
    "plt.scatter(features_scaled[labels==1,0], features_scaled[labels==1,1], c='r')\n",
    "plt.xlabel('Zero Crossing Rate (scaled)')\n",
    "plt.ylabel('Energy (scaled)')\n",
    "plt.legend(('Class 0', 'Class 1'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listen to onsets assigned to Class 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "x_with_beeps = mir_eval.sonify.clicks(onset_times[labels==0], fs, length=len(x))\n",
    "ipd.Audio(x + x_with_beeps, rate=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "x_with_beeps = mir_eval.sonify.clicks(onset_times[labels==1], fs, length=len(x))\n",
    "ipd.Audio(x + x_with_beeps, rate=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affinity Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model = sklearn.cluster.AffinityPropagation(random_state=None)\n",
    "labels = model.fit_predict(features_scaled)\n",
    "\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plt.scatter(features_scaled[labels==0,0], features_scaled[labels==0,1], c='b')\n",
    "plt.scatter(features_scaled[labels==1,0], features_scaled[labels==1,1], c='r')\n",
    "plt.scatter(features_scaled[labels==2,0], features_scaled[labels==2,1], c='y')\n",
    "plt.xlabel('Zero Crossing Rate (scaled)')\n",
    "plt.ylabel('Energy (scaled)')\n",
    "plt.legend(('Class 0', 'Class 1', 'Class 2'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "x_with_beeps = mir_eval.sonify.clicks(onset_times[labels==0], fs, length=len(x))\n",
    "ipd.Audio(x + x_with_beeps, rate=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "x_with_beeps = mir_eval.sonify.clicks(onset_times[labels==1], fs, length=len(x))\n",
    "ipd.Audio(x + x_with_beeps, rate=fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "x_with_beeps = mir_eval.sonify.clicks(onset_times[labels==2], fs, length=len(x))\n",
    "ipd.Audio(x + x_with_beeps, rate=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
