{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#262626; text-align: center;\">\n",
    "<img src=\"https://fiapfunctions.blob.core.windows.net/datasets/capa.png\">\n",
    "</div>\n",
    "\n",
    "# Practices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir audios\n",
    "\n",
    "!curl https://meriatdatasets.blob.core.windows.net/public/digital-audio-processing/OSR_us_000_0010_8k.wav -o audios/OSR_us_000_0010_8k.wav\n",
    "!curl https://meriatdatasets.blob.core.windows.net/public/digital-audio-processing/simple_loop.wav -o audios/simple_loop.wav\n",
    "!curl https://meriatdatasets.blob.core.windows.net/public/digital-audio-processing/brahms_hungarian_dance_5.mp3 -o audios/brahms_hungarian_dance_5.mp3\n",
    "!curl https://meriatdatasets.blob.core.windows.net/public/digital-audio-processing/busta_rhymes_hits_for_days.mp3 -o audios/busta_rhymes_hits_for_days.mp3\n",
    "!curl https://meriatdatasets.blob.core.windows.net/public/digital-audio-processing/c_strum.wav -o audios/c_strum.wav\n",
    "!curl https://meriatdatasets.blob.core.windows.net/public/digital-audio-processing/oboe_c6.wav -o audios/oboe_c6.wav\n",
    "!curl https://meriatdatasets.blob.core.windows.net/public/digital-audio-processing/seis.wav -o audios/seis.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "from scipy.fftpack import fft\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "plt.rcParams.update({'font.size': 18})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, sr = librosa.load('audios/seis.wav')\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "librosa.display.waveplot(x, sr=sr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio('audios/seis.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate an amplitude modulated signal:\n",
    "x = np.linspace(0, 10, 501)\n",
    "ampl = np.exp(-(x - 3.5)**2 / 0.8)\n",
    "y = np.sin(x * 25) * ampl\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(x, y, label='signal')\n",
    "plt.plot(x, ampl, ':', label='amplitude')\n",
    "plt.xlabel('time', fontsize=16)\n",
    "plt.ylabel('value', fontsize=16)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate = 8000 # amostras por segundo\n",
    "T = 5.0 # segundos\n",
    "t = np.linspace(0, T, int(T*sample_rate), endpoint=False) # time variable\n",
    "x = 0.5 * np.sin(2 * np.pi * 440 * t) #uma onda senoidal pura de 440 Hz (ISO 16!)\n",
    "\n",
    "np.linspace(0, T, int(T*sample_rate), endpoint=False) # time variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(x, rate=sample_rate) # Carrega a onda de 440Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = 0.5*np.sin(2*np.pi*1000*t) #uma onda senoidal pura de 1000 Hz\n",
    "ipd.Audio(y, rate=sample_rate) # Carrega a onda de 1000Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = x + y\n",
    "ipd.Audio(xy, rate=sample_rate) # carrega o som de x + y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sinais no domínio do Tempo *vs* domínio da Frequência\n",
    "\n",
    "### Sinais no domínio do tempo\n",
    "\n",
    "Quando reproduzimos os sons digitais, transformamos os sinais em ondas mecânicas, que na verdade representam as variações da amplitude no tempo.\n",
    "\n",
    "Desenhamos as variações das amplitudes no tempo dos sinais x, y e xy, seguindo 1/8000 amostras por segundo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 4))\n",
    "plt.plot(x[:int(0.01*8000)])\n",
    "plt.xlabel('Amostras', fontsize = 16)\n",
    "plt.ylabel('Amplitude', fontsize = 16)\n",
    "plt.title('Sinal X no domínio do Tempo', fontsize = 22)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 4))\n",
    "plt.plot(y[:int(0.01*8000)])\n",
    "plt.xlabel('Amostras', fontsize = 16)\n",
    "plt.ylabel('Amplitude', fontsize = 16)\n",
    "plt.title('Sinal Y no domínio do Tempo', fontsize = 22)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 4))\n",
    "plt.plot(xy[:int(0.01*8000)])\n",
    "plt.xlabel('Amostras', fontsize = 16)\n",
    "plt.ylabel('Amplitude', fontsize = 16)\n",
    "plt.title('Sinal XY no domínio do Tempo', fontsize = 22)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sinal_audio, sample_rate_sinal_audio = librosa.load('audios/OSR_us_000_0010_8k.wav', sr=None)\n",
    "print(sample_rate_sinal_audio)\n",
    "plt.figure(figsize=(18, 6))\n",
    "plt.plot(sinal_audio[:int(3.5*sample_rate_sinal_audio)]) # 3.5 segundos do áudio\n",
    "plt.xlabel('Amostras', fontsize = 16)\n",
    "plt.ylabel('Amplitude', fontsize = 16)\n",
    "plt.title('Amostra do sinal OSR_us_000_0010_8k no domínio do Tempo', fontsize = 22)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 6))\n",
    "plt.plot(sinal_audio)\n",
    "plt.xlabel('Amostras', fontsize = 16)\n",
    "plt.ylabel('Amplitude', fontsize = 16)\n",
    "plt.title('Sinal OSR_us_000_0010_8k no domínio do Tempo', fontsize = 22)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(sinal_audio, rate=sample_rate_sinal_audio) # carrega o som do openspeech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Domínio da Frequência\n",
    "\n",
    "## Transformações entre tempo e domínio de frequência (FFT, PSD, onda)\n",
    "\n",
    "A análise de Fourier é um campo de estudo utilizado para analisar a periodicidade em sinais (periódicos). Se um sinal contém componentes que são periódicos de natureza, a análise fourier pode ser usada para decompor este sinal em seus componentes periódicos. A análise de Fourier nos diz qual é a frequência desses componentes periódicos.\n",
    "\n",
    "Por exemplo, se medirmos seu batimento cardíaco e no momento da medição você tiver uma frequência cardíaca de 60 batidas /minuto, o sinal terá uma frequência de $\\large 1Hz$ (Período de $\\large 1S$ = frequência de $\\large 1Hz$). Se você está fazendo ao mesmo tempo, alguma tarefa repetitiva onde você move os dedos $\\large 0.5Hz$ a $\\large 2S$ cada dois $\\large 0.5Hz$ segundos, o sinal que vai para sua mão terá uma frequência de (Período de = frequência de ). Um eletrodo colocado em seu braço.vai medir a combinação desses dois sinais. E uma análise fourier realizada nos sinais combinados, nos mostrará um pico no espectro de frequências a $\\large 0,5Hz$ e um a $\\large 1Hz$.\n",
    "\n",
    "Assim, dois (ou mais) sinais diferentes (com diferentes frequências, amplitudes, etc) podem ser misturados para formar um novo sinal composto. O novo sinal então consiste em todos os seus sinais componentes.\n",
    "\n",
    "O inverso também é verdade, cada sinal – não importa o quão complexo pareça – pode ser decomposto em uma soma de seus sinais mais simples. Estes sinais mais simples são funções trigonométricas (ondas sine e cosine). Isso foi descoberto (em 1822) por Joseph Fourier e é sobre o que é a [análise de Fourier](https://betterexplained.com/articles/an-interactive-guide-to-the-fourier-transform/). A função matemática que transforma um sinal do domínio do tempo para o domínio de frequência é chamada de Fourier Transform, e a função que faz o oposto é chamada de Inverso Fourier Transform.\n",
    "\n",
    "Se você quiser saber como funciona a transformação de Fourier, a explicação lindamente animada da [3blue1brown](https://www.youtube.com/watch?v=spUNpyF58BY) lhe dará mais informações. Para uma visão mais pythônica, temos o [An Intuitive Introduction to the Fourier Transform and FFT](https://www.youtube.com/watch?v=YEwIjyOKFQ4).\n",
    "\n",
    "Abaixo, podemos ver isso em ação. Temos cinco ondas de seno (sinais azuis) com amplitudes 4, 6, 8, 10 e 14 e frequências 6.5, 5, 3, 1,5 e $\\large 1Hz$. Combinando esses sinais, formamos um novo sinal composto (preto). O Fourier Transform transforma este sinal no domínio de frequência (sinal vermelho) e nos mostra em quais frequências o componente sinaliza oscilar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fft_values(y_values, T, N, f_s):\n",
    "    f_values = np.linspace(0.0, 1.0/(2.0*T), N//2)\n",
    "    fft_values_ = fft(y_values)\n",
    "    fft_values = 2.0/N * np.abs(fft_values_[0:N//2])\n",
    "    return f_values, fft_values\n",
    " \n",
    "t_n = 10; N = 1000; T = t_n / N; f_s = 1/T\n",
    " \n",
    "x_value = np.linspace(0,t_n,N)\n",
    "amplitudes = [4, 6, 8, 10, 14]\n",
    "frequencies = [6.5, 5, 3, 1.5, 1]\n",
    "y_values = [amplitudes[ii]*np.sin(2*np.pi*frequencies[ii]*x_value) for ii in range(0,len(amplitudes))]\n",
    "composite_y_value = np.sum(y_values, axis=0)\n",
    " \n",
    "f_values, fft_values = get_fft_values(composite_y_value, T, N, f_s)\n",
    " \n",
    "colors = ['k', 'b', 'b', 'b', 'b', 'b', 'b', 'b', 'b']\n",
    " \n",
    "fig = plt.figure(figsize=(14,12))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "plt.title('A signal (black) consisting of multiple component signals (blue) with different frequencies (red).', fontsize=18)\n",
    "ax.set_xlabel(\"\\nTime [s]\", fontsize=16)\n",
    "ax.set_ylabel(\"\\nFrequency [Hz]\", fontsize=16)\n",
    "ax.set_zlabel(\"\\nAmplitude\", fontsize=16)\n",
    " \n",
    "y_values_ = [composite_y_value] + list(reversed(y_values))\n",
    "frequencies = [1, 1.5, 3, 5, 6.5]\n",
    " \n",
    "try:\n",
    "    for ii in range(0,len(y_values_)-1):\n",
    "        signal = y_values_[ii]\n",
    "        color = colors[ii]\n",
    "        length = signal.shape[0]\n",
    "        xx=np.linspace(0,10,1000)\n",
    "        yy=np.array([frequencies[ii]]*length)\n",
    "        zz=signal\n",
    "\n",
    "        if ii == 0:\n",
    "            linewidth = 4\n",
    "        else:\n",
    "            linewidth = 2\n",
    "        ax.plot(list(xx), list(yy), zs=list(zz), linewidth=linewidth, color=color)\n",
    "\n",
    "        xx=[10]*75\n",
    "        yy=f_values[:75]\n",
    "        zz = fft_values[:75]*3\n",
    "        ax.plot(list(xx), list(yy), zs=list(zz), linewidth=2, color='red')\n",
    "\n",
    "        plt.tight_layout()\n",
    "except Exception as ex:\n",
    "    print(ex)\n",
    "    \n",
    "ax.view_init(60, 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O Fast Fourier Transform (FFT) é um algoritmo eficiente para calcular o Discreto Fourier Transform (DFT) e é o padrão de fato para calcular um Fourier Transform. Está presente em quase todas as bibliotecas e pacotes de computação científica, em todas as linguagens de programação.\n",
    "\n",
    "Hoje em dia a transformação de Fourier é uma ferramenta matemática indispensável usada em quase todos os aspectos do nosso cotidiano. Na próxima seção, veremos como podemos usar a FFT e outras técnicas de análise de sinais estocásticos para classificar séries de tempo e sinais.\n",
    "\n",
    "## O FFT em Python\n",
    "\n",
    "Em Python, o FFT de um sinal pode ser calculado com a biblioteca SciPy. Abaixo, podemos ver como podemos usar o SciPy para calcular a FFT do sinal composto acima, e recuperar os valores de frequência de seus sinais componentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,10))\n",
    "plt.plot(f_values, fft_values, linestyle='-', color='blue')\n",
    "plt.xlabel('Frequency [Hz]', fontsize=16)\n",
    "plt.ylabel('Amplitude', fontsize=16)\n",
    "plt.title(\"Frequency domain of the signal\", fontsize=22)\n",
    "plt.suptitle('O FFT do nosso sinal composto o transforma do domínio temporal para o Domínio de Frequência',fontsize=18, y=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma vez que nosso sinal $\\large f_s 100Hz$ é amostrado a uma taxa de, $\\large f_s / 2 = 50Hz$ a FFT devolverá o espectro de frequência até outra. Quanto maior for a taxa de amostragem, maior a frequência máxima é a FFT pode calcular.\n",
    "\n",
    "Na função acima, a função retorna um vetor de frequências complexas valorizadas. Uma vez que são complexos valorizados, eles conterão uma parte real e imaginária. A parte real do valor complexo corresponde à magnitude, e à parte imaginária com a fase do sinal. Como só estamos interessados na magnitude das amplitudes, usamos para tomar a parte real do espectro de `frequências.get_fft_valuesscipy.fftpack.fftnp.abs()`.\n",
    "\n",
    "O FFT de um sinal de entrada de pontos N, devolverá um vetor de pontos N. A primeira metade deste vetor (N/2 pontos) contém os valores úteis do $\\large f_s / 2$ espectro de frequência de 0 Hz até a frequência de Nyquist de . A segunda metade contém a conjugada complexa e pode ser desconsiderada, uma vez que não fornece nenhuma informação útil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 8))\n",
    "\n",
    "X = librosa.stft(x)\n",
    "\n",
    "Xdb = librosa.amplitude_to_db(np.abs(X))\n",
    "Xdb = librosa.amplitude_to_db(np.abs(X))\n",
    "\n",
    "librosa.display.specshow(Xdb, sr=sample_rate, x_axis='time', y_axis='hz')\n",
    "plt.xlabel('Time', fontsize = 16), plt.ylabel('Hz', fontsize = 16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 8))\n",
    "\n",
    "Y = librosa.stft(y)\n",
    "Ydb = librosa.amplitude_to_db(np.abs(Y))\n",
    "librosa.display.specshow(Ydb, sr=sample_rate, x_axis='time', y_axis='hz')\n",
    "plt.xlabel('Time', fontsize = 16), plt.ylabel('Hz', fontsize = 16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 8))\n",
    "\n",
    "XY = librosa.stft(xy)\n",
    "XYdb = librosa.amplitude_to_db(np.abs(XY))\n",
    "librosa.display.specshow(XYdb, sr=sample_rate, x_axis='time', y_axis='hz')\n",
    "plt.xlabel('Time', fontsize = 16), plt.ylabel('Hz', fontsize = 16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 8))\n",
    "\n",
    "SINAL_AUDIO = librosa.stft(sinal_audio)\n",
    "SINAL_AUDIOdb = librosa.amplitude_to_db(np.abs(SINAL_AUDIO))\n",
    "librosa.display.specshow(SINAL_AUDIOdb, sr=sample_rate_sinal_audio, x_axis='time', y_axis='hz')\n",
    "plt.xlabel('Time', fontsize = 16), plt.ylabel('Hz', fontsize = 16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 8))\n",
    "\n",
    "SINAL_AUDIO = librosa.stft(sinal_audio[0:int(3.5 * sample_rate)])\n",
    "SINAL_AUDIOdb = librosa.amplitude_to_db(np.abs(SINAL_AUDIO))\n",
    "librosa.display.specshow(SINAL_AUDIOdb, sr=sample_rate_sinal_audio, x_axis='time', y_axis='hz')\n",
    "plt.xlabel('Time', fontsize = 16), plt.ylabel('Hz', fontsize = 16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sinais no domínio da Frequência *vs* log-Mels\n",
    "\n",
    "O ouvido humano não distingue as frequencias com a mesma precisão e não ouve todas as frequências com a mesma intensidade.\n",
    "\n",
    "A cóclea é o orgão é responsável pela transformação dos sinais acústicos em sinais neurais. É um canal espiral ósseo que está dividido e possui uma forma que lembra a concha de um caracol, localizado no interior do osso temporal (estrutura óssea densa, altamente mineralizada e de acesso difícil).\n",
    "\n",
    "<div align=\"center\" style=\"width: 100%;\">\n",
    "    <img src=\"imgs/ear-diagram-picture.jpg\" style=\"width: 900px\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percepção da Cóclea comparada com o Piano\n",
    "\n",
    "<div align=\"center\" style=\"width: 100%;\">\n",
    "    <img src=\"imgs/Coclea-Piano-Graphics.jpg\" style=\"width: 550px\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percepção da Cóclea versus distância percorrida no canal\n",
    "\n",
    "<div align=\"center\" style=\"width: 100%;\">\n",
    "    <img src=\"imgs/tonotopic-principal-of-the-cochlea.jpg\" style=\"width: 350px\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assim, várias escalas baseadas na percepção surgiram no passado, a fim de simular este efeito natural que existe no humano. uma delas é a [escala Mel](https://en.wikipedia.org/wiki/Mel_scale). Ela segue este mapa entre as frequências naturais do som e as percebidas pelo ouvido humano:\n",
    "\n",
    "\n",
    "<div align=\"center\" style=\"width: 100%;\">\n",
    "    <img src=\"imgs/Mel-Hz_plot.svg\" style=\"width: 800px\">\n",
    "</div>\n",
    "\n",
    "Para converter Hertz ($f$) em Mel ($m$) nós usamos as seguintes equações:\n",
    "\n",
    "$$\\Large m = 2595 \\log_{10} (1 + \\frac{f}{700})$$\n",
    "\n",
    "$$\\Large f = 700 (10^{m/2595} - 1) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Taxa de cruzamento por zero\n",
    "\n",
    "A taxa de cruzamento por zero é uma característica que nos ajuda a entender o conteúdo da frequência do sinal. Esta taxa pode ser calculada por:\n",
    "\n",
    "$$ Z = \\frac{1}{2(N-1)} \\sum_{i=1}^{N-1} \\left|\\text{sign}(s_i) - \\text{sign}(s_{i-1})\\right| \\\\ \\text{Onde: } \\text{sign}(s_i) = \\left\\{ \\begin{array}{rl} 1, & \\text{se } s_i \\geq 0\\\\ -1, & \\mbox{se } s_i < 0 \\end{array} \\right. $$\n",
    "\n",
    "Em relação a taxa de cruzamento por zero, devemos considerar que $0 \\leq Z \\leq 1$, ou seja, quando mais próximo $Z$ for de 1, significa que o conteúdo em relação a frequência é maior. \n",
    "\n",
    "Utilizando o pacote librosa, é possível computar a quantidade de travessias do zero que ocorreram em um dado sinal. No trecho de código abaixo, utilizando o método zero_crossings, informamos um sinal (aqui representado por signal), e obtemos um array com todas as incidências calculadas.\n",
    "\n",
    "```python\n",
    "zero_crossings = librosa.zero_crossings(signal, pad=False)\n",
    "print(sum(zero_crossings))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Autocorrelation\n",
    "\n",
    "A autocorrelação ([autocorrelation](http://en.wikipedia.org/wiki/Autocorrelation)) de um sinal descreve a semelhança de um sinal contra uma versão diferenciada de tempo de si mesmo. Para um sinal $x$, a autocorrelação $r$ é:\n",
    "\n",
    "$\\Large r(k) = \\sum_n x(n) x(n-k) $, onde $k$ é frequentemente chamado de parâmetro **lag**. \n",
    "\n",
    "A autocorrelação é útil para encontrar padrões repetidos em um sinal. Por exemplo, em problemas de defasagem curta, a autocorrelação pode nos dizer algo sobre a frequência fundamental do sinal. Para atrasos mais longos, a autocorrelação pode nos dizer coisas como informações sobre o ritmo de um sinal musical.\n",
    "\n",
    "O processo de autocorrelação em sinais de áudio, descreve a semelhança de um sinal comparando uma versão sua deslocada no tempo (segmentos). O resultado da autocorrelação é uma medida de similaridade entre os segmentos comparados. Dado um sinal $x$, sua autocorrelação $r$ é definida matematicamente por:\n",
    "\n",
    "A autocorrelação é muito utilizada para encontrar padrões repetidos em um mesmo sinal \\cite{rabiner2010theory}. O resultado da autocorrelação fornece informações sobre a frequência fundamental, ou até mesmo sobre o ritmo no caso de um sinal musical.\n",
    "\n",
    "É possível calcular a autocorrelação de um sinal utilizando a biblioteca librosa, informando apenas o sinal (signal) e o tamanho máximo do sinal a ser considerado. O resultado será um array contendo os valores calculados para cada segmento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, sr = librosa.load('audios/c_strum.wav')\n",
    "ipd.Audio(x, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.waveplot(x, sr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `numpy.correlate`\n",
    "\n",
    "Há duas maneiras de calcular a autocorrelação em Python. O primeiro é o método [`numpy.correlate`](http://docs.scipy.org/doc/numpy/reference/generated/numpy.correlate.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.correlate(x, x, mode='full')[len(x)-1:]\n",
    "print(x.shape, r.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `librosa.autocorrelate`\n",
    "\n",
    "O segundo método é utilizar diretamente o [`librosa.autocorrelate`](http://bmcfee.github.io/librosa/generated/librosa.core.autocorrelate.html#librosa.core.autocorrelate):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = librosa.autocorrelate(x, max_size=10000)\n",
    "print(r.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(r)\n",
    "plt.xlabel('Lag (samples)')\n",
    "plt.xlim(0, 10000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`librosa.autocorrelate` convenientemente só mantém metade da função de autocorrelação, uma vez que a função de autocorrelação é simétrica. Além disso, a utilização do parâmetro `max_size` evita cálculos.\n",
    "\n",
    "---\n",
    "\n",
    "## Pitch Estimation\n",
    "\n",
    "A autocorrelação é usada para encontrar padrões repetidos dentro de um sinal. Para sinais musicais, um padrão repetido pode corresponder a um período de pitch, ou no geral, o tom da música. \n",
    "\n",
    "Podemos, portanto, usar a função de autocorrelação para estimar o tom em um sinal musical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, sr = librosa.load('audios/oboe_c6.wav')\n",
    "ipd.Audio(x, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = librosa.autocorrelate(x, max_size=5000)\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(r[:200])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A autocorrelação sempre tem um máximo de zero, ou seja, zero lag. Queremos identificar o máximo fora do pico centrado em zero. Portanto, podemos escolher apenas pesquisar dentro de uma gama de arremessos razoáveis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midi_hi = 120.0\n",
    "midi_lo = 12.0\n",
    "f_hi = librosa.midi_to_hz(midi_hi)\n",
    "f_lo = librosa.midi_to_hz(midi_lo)\n",
    "t_lo = sr/f_hi\n",
    "t_hi = sr/f_lo\n",
    "\n",
    "print(f_lo, f_hi)\n",
    "print(t_lo, t_hi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r[:int(t_lo)] = 0\n",
    "r[int(t_hi):] = 0\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(r[:1400])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encontra o ponto de valor máximo:\n",
    "\n",
    "t_max = r.argmax()\n",
    "print(t_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste ponto, vamos estimar o **tom** em Hertz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float(sr)/t_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na verdade, isso é muito próximo da frequência real de um **C6**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.midi_to_hz(84)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\" style=\"width: 100%;\">\n",
    "    <img src=\"http://newt.phys.unsw.edu.au/jw/graphics/notes.GIF\">\n",
    "    <h4 style=\"font-family: courier; font-size: .8em;\">ref: http://newt.phys.unsw.edu.au/jw/notes.html</h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genre Recognition\n",
    "\n",
    "Carregando 30 segundos para verificação/exploração."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_brahms = 'audios/brahms_hungarian_dance_5.mp3'\n",
    "\n",
    "x_brahms, sr_brahms = librosa.load(filename_brahms, duration=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_busta = 'audios/busta_rhymes_hits_for_days.mp3'\n",
    "\n",
    "x_busta, sr_busta = librosa.load(filename_busta, duration=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(x_brahms, rate=sr_brahms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(x_busta, rate=sr_busta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 4))\n",
    "librosa.display.waveplot(x_brahms, sr_brahms)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 4))\n",
    "librosa.display.waveplot(x_busta, sr_busta)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computar o melspectrogram de potência:\n",
    "S_brahms = librosa.feature.melspectrogram(x_brahms, sr=sr_brahms, power=2.0)\n",
    "S_busta = librosa.feature.melspectrogram(x_busta, sr=sr_busta, power=2.0)\n",
    "\n",
    "# Converter amplitude em decibéis:\n",
    "Sdb_brahms = librosa.power_to_db(S_brahms)\n",
    "Sdb_busta = librosa.power_to_db(S_busta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 6))\n",
    "librosa.display.specshow(Sdb_brahms, sr=sr_brahms, x_axis='time', y_axis='mel')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 6))\n",
    "librosa.display.specshow(Sdb_busta, sr=sr_busta, x_axis='time', y_axis='mel')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debulhando o Spectrogram\n",
    "\n",
    "Ref: [link to sounds](http://www.ultimaserial.com/UltimaSound.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl https://meriatdatasets.blob.core.windows.net/public/digital-audio-processing/hello.wav -o audios/hello.wav\n",
    "!curl https://meriatdatasets.blob.core.windows.net/public/digital-audio-processing/head.wav -o audios/head.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mel_spec(file_name):\n",
    "    x, sr = librosa.load(f'audios/{file_name}.wav')\n",
    "    plt.figure(figsize=(16, 2))\n",
    "    librosa.display.waveplot(x, sr)\n",
    "    plt.axis(False)\n",
    "    plt.show()\n",
    "\n",
    "    S = librosa.feature.melspectrogram(x, sr=sr)\n",
    "    Sdb = librosa.power_to_db(S)\n",
    "\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    librosa.display.specshow(Sdb, sr=sr, x_axis='time', y_axis='mel')\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mel_spec('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mel_spec('head')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
